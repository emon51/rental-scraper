# Airbnb Rental Scraper

A high-performance, concurrent web scraping system built with Go and ChromeDP for collecting and analyzing rental property data from Airbnb across multiple cities.

## Project Overview

This scraper is designed to collect rental property listings from Airbnb, process the data, store it in PostgreSQL and generate market insights. It demonstrates production-grade architecture with concurrent scraping, rate limiting, data cleaning, and robust error handling.


## Project Structure

```
rental-scraper/
├── main.go                     # Application entry point
├── config/
│   └── config.go               # Configuration management
├── models/
│   └── listing.go              # Data models
├── scraper/
│   ├── scraper.go              # Scraping logic
│   └── selectors.go            # CSS selectors
├── services/
│   ├── pipeline.go             # Pipeline orchestration
│   ├── scraper_service.go      # Concurrent scraping
│   ├── filter.go               # Data cleaning
│   └── insights.go             # Statistics generation
├── storage/
│   ├── csv_writer.go           # CSV export
│   └── postgres_writer.go      # PostgreSQL storage
├── utils/
│   ├── browser.go              # Browser context
│   └── logger.go               # Logging utility
├── go.mod                      # Go module dependencies
├── go.sum                      # Dependency checksums (auto-generated by Go)
├── docker-compose.yml          # PostgreSQL setup
└── README.md                   # Documentation file
```

## Key Features

- **Concurrent Scraping** - Multiple locations + descriptions in parallel
- **Rate Limiting** - Respects server with delays and semaphores  
- **Pagination** - Scrapes multiple pages per location  
- **Data Cleaning** - Removes duplicates and validates data  
- **Dual Storage** - CSV + PostgreSQL  
- **Market Insights** - Automatic statistical analysis  
- **Error Recovery** - Graceful failure handling  
- **Logging** - Full activity logs in `scraper.log` 

## Requirements

- Go 1.21 or higher
- Docker and Docker Compose
- Chrome/Chromium browser
- PostgreSQL (via Docker)

## Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/emon51/rental-scraper.git
```
### 2. Change directory
```bash
cd rental-scraper
```

### 3. Install Dependencies
```bash
go mod download
```

### 4. Start PostgreSQL
```bash
docker-compose up -d
```

Verify PostgreSQL is running:
```bash
docker ps
```

### 5. Run the Scraper
```bash
go run main.go
```

### Access PostgreSQL
```bash
# Connect to database
docker exec -it rental_scraper_db psql -U postgres -d rental_scraper

# Query listings
SELECT title, price, location, rating FROM listings LIMIT 10;

# Count by location
SELECT location, COUNT(*) FROM listings GROUP BY location ORDER BY COUNT(*) DESC;
```


## Configuration

Edit `config/config.go` to customize:
```go
BaseURL:         "https://www.airbnb.com/s/%s/homes"
ListingsPerPage: 5          // Listings to scrape per page
PagesToScrape:   2          // Number of pages per location
PageTimeout:     600        // Timeout in seconds
RequestDelay:    2          // Delay between requests (seconds)
Headless:        true       // Run browser in headless mode
MaxConcurrent:   3          // Concurrent location scrapers
```

### Locations

Add or remove cities in `config.go`:
```go
Locations: []LocationConfig{
    {Slug: "Kuala-Lumpur", DisplayName: "Kuala Lumpur, Malaysia"},
    {Slug: "Bangkok", DisplayName: "Bangkok, Thailand"},
    // Add more...
}
```

## Data Fields Scraped

| Field | Description |
|-------|-------------|
| Platform | Source platform (Airbnb) |
| Title | Property title |
| Price | Nightly rate (numeric) |
| Location | City and country |
| Rating | Guest rating (1-5 scale) |
| URL | Direct link to listing |
| Description | Property description |

## Storage

### CSV Output

Data is saved to `listings.csv` in the project root:
```csv
Platform,Title,Price,Location,Rating,URL,Description
Airbnb,Modern Studio,120,Bangkok Thailand,4.85,https://...,Cozy studio...
```

### PostgreSQL Schema
```sql
CREATE TABLE listings (
    id SERIAL PRIMARY KEY,
    platform VARCHAR(50) NOT NULL,
    title TEXT NOT NULL,
    price NUMERIC(10, 2),
    location VARCHAR(255),
    rating NUMERIC(3, 2),
    url TEXT UNIQUE NOT NULL,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Indexes for performance
CREATE INDEX idx_listings_price ON listings(price);
CREATE INDEX idx_listings_location ON listings(location);
CREATE INDEX idx_listings_rating ON listings(rating);
```



## Architecture

### Design Patterns

- **Factory Pattern** - Browser context creation
- **Strategy Pattern** - Different scraping strategies per platform
- **Pipeline Pattern** - Sequential data processing stages
- **Repository Pattern** - Data storage abstraction

## Performance

### Concurrency Features
**Level 1:** 3 cities scraped simultaneously  
**Level 2:** 3 descriptions fetched per city simultaneously
```
Main Thread
    │
    ├─ Location 1 (goroutine) ──┐
    ├─ Location 2 (goroutine) ──┼─ Semaphore (limit: 3)
    ├─ Location 3 (goroutine) ──┘
    └─ ... (wait for all)
```

### Data Flow
```
Scraper → Filter → CSV Writer
                 ↓
            PostgreSQL Writer
                 ↓
            Insight Generator
```
## Troubleshooting

### PostgreSQL Connection Failed
```bash
# Restart PostgreSQL
docker-compose down
docker-compose up -d

# Check status
docker ps
```

### Context Deadline Exceeded

Increase timeout in `config.go`:
```go
PageTimeout: 900  // Increase to 15 minutes
```

### No Data Scraped

1. Run with `Headless: false` to see browser
2. Check if Airbnb changed HTML structure
3. Verify network connectivity


## Architecture

### Design Patterns

- **Pipeline Pattern** - Sequential data processing
- **Factory Pattern** - Browser context creation
- **Repository Pattern** - Data storage abstraction
- **Concurrent Pattern** - Goroutines with semaphores

### SOLID Principles

- **Single Responsibility** - Each service has one job  
- **Open/Closed** - Extensible without modification  
- **Liskov Substitution** - Interfaces properly implemented  
- **Interface Segregation** - Focused interfaces  
- **Dependency Inversion** - Depends on abstractions  


## Dependencies
Browser automation
```
github.com/chromedp/chromedp
```
PostgreSQL driver
```
github.com/lib/pq            
```

## License

This project is for educational purposes only.
